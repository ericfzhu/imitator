import Image from 'next/image';
import Link from 'next/link';

export default function Home() {
	return (
		<main className="flex min-h-screen flex-col items-center gap-12 bg-white p-24 text-black">
			<section className="flex max-w-3xl flex-col items-center gap-8">
				<h1 className="max-w-4xl flex-wrap text-center text-lg lg:text-3xl">
					Imitator: <span className="text-accent-500">Im</span>age-to-<span className="text-accent-500">I</span>mage{' '}
					<span className="text-accent-500">T</span>ransl<span className="text-accent-500">at</span>i
					<span className="text-accent-500">o</span>n with a <span className="text-accent-500">R</span>esNeXt-based GAN
				</h1>

				<div className="flex gap-2 text-sm">
					<Link
						href="https://github.com/ericfzhu/imitator"
						className="border-[1px] border-accent-700 bg-accent-500 px-4 py-1 uppercase text-white duration-300 hover:bg-accent-400"
						target="_blank">
						Code
					</Link>
					<Link
						href="https://huggingface.co/ericfzhu/imitator"
						className="border-[1px] border-accent-700 bg-accent-500 px-4 py-1 uppercase text-white duration-300 hover:bg-accent-400"
						target="_blank">
						HuggingFace
					</Link>
				</div>
			</section>

			<section className="flex max-w-3xl flex-col gap-2">
				<h2 className="text-center text-3xl">Abstract</h2>
				<p>
					This work presents a ResNext-based Generative Adversarial Network for image-to-image translation. The model is designed to
					translate low-quality images captured by mobile phones into high-quality images resembling those captured by a DSLR camera. The
					generator network employs convolutional blocks and deconvolutional layers to learn the mapping between the mobile and DSLR quality
					image domains. The discriminator network is a CNN that learns to distinguish between real and fake images generated by the
					generator. The training process involves a two-stage approach, where the generator is trained first to generate high-quality
					images, and then the discriminator is trained to distinguish between real and fake images. The GAN is trained using a combination
					of adversarial loss and L1 loss to encourage the generator to produce images that produce realistic results.
				</p>
			</section>

			<section className="flex max-w-3xl flex-col gap-2">
				<h2 className="text-center text-3xl">Demo</h2>
				<p>
					Praesent lacus risus, facilisis in auctor non, lobortis sit amet orci. Aenean efficitur justo eu rhoncus vehicula. Pellentesque
					augue ligula, efficitur sit amet arcu eu, sodales suscipit neque. Aliquam at facilisis mi, eu tempor mauris. Fusce turpis est,
					vulputate ut aliquam id, pulvinar vel enim. Integer at mauris quis ex ultrices malesuada. Nam hendrerit, lorem aliquam tempor
					laoreet, velit nulla consectetur ex, et finibus dolor nulla eu orci.
				</p>
			</section>

			<section className="flex max-w-3xl flex-col gap-2">
				<h2 className="text-center text-3xl">Architectures</h2>
				<div className="flex flex-col">
					<div>
						<h3 className="text-center text-2xl">Generator</h3>
						<Image src="/generator.png" alt="ResNeXt-based Generator" width={500} height={500} className="w-full" />
					</div>
					<div>
						<h3 className="text-center text-2xl">Discriminator</h3>
						<Image src="/discriminator.png" alt="ResNeXt-based Generator" width={500} height={500} className="w-full" />
					</div>
				</div>
			</section>
		</main>
	);
}
